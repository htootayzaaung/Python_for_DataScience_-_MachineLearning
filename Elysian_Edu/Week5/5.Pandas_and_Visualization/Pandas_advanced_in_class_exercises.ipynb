{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4165706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T14:42:41.172861Z",
     "start_time": "2022-07-29T14:42:40.503512Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c14d9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T14:50:21.247010Z",
     "start_time": "2022-07-29T14:50:20.378164Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "end = datetime.datetime(2017, 1, 11)\n",
    "\n",
    "df = web.DataReader(\"AAPL\", 'yahoo', start, end)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a75a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T14:50:29.173988Z",
     "start_time": "2022-07-29T14:50:29.133414Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcf183",
   "metadata": {},
   "source": [
    "# Pandas Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cb41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T14:42:44.871315Z",
     "start_time": "2022-07-29T14:42:44.859250Z"
    }
   },
   "outputs": [],
   "source": [
    "df_student = pd.read_csv('resources/pandas_exercise_student.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1df948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T14:42:45.367505Z",
     "start_time": "2022-07-29T14:42:45.348738Z"
    }
   },
   "outputs": [],
   "source": [
    "df_student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c352ab",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Group the dataframe based on school code and get mean, min, and max value of age for each school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988a07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "              age        \n",
      "             mean min max\n",
      "school_code              \n",
      "s001         12.5  12  13\n",
      "s002         13.0  12  14\n",
      "s003         13.0  13  13\n",
      "s004         12.0  12  12\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df_student = pandas.read_csv('resources/pandas_exercise_student.csv',index_col = 0)\n",
    "\n",
    "print(df_student)\n",
    "\n",
    "grouped = df_student.groupby('school_code').agg({\"age\":['mean', 'min', 'max']})\n",
    "\n",
    "print(grouped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89865f",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Write a Pandas program to split the following given dataframe into groups based on school code and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b12fd05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('s001', 'V')\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "('s001', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S4        s001    VI  Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S4  street1  \n",
      "('s002', 'V')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "('s003', 'VI')\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "('s004', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df_student = pandas.read_csv('resources/pandas_exercise_student.csv',index_col = 0)\n",
    "\n",
    "grouped = df_student.groupby([\"school_code\", \"class\"])\n",
    "\n",
    "for school_code, className in grouped:\n",
    "    print(school_code)\n",
    "    print(className)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ad07a",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Write a Pandas program to split the following given dataframe into groups based on school code and call a specific group with the name of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "418257e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df_student = pandas.read_csv('resources/pandas_exercise_student.csv',index_col = 0)\n",
    "\n",
    "grouped = df_student.groupby([\"school_code\"])\n",
    "\n",
    "print(grouped.get_group(\"s001\"))\n",
    "\n",
    "print(grouped.get_group(\"s002\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bfe51",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Write a Pandas program to split a dataset, **group by one column and get mean, min, and max values by group**. \n",
    "\n",
    "\n",
    "For example, Using the following dataset **find the mean, min, and max values of purchase amount (purch_amt) group by customer id (customer_id).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce079765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T15:21:52.553318Z",
     "start_time": "2022-07-29T15:21:52.527673Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 message\n",
      "0                                             My Account\n",
      "1                                                      4\n",
      "2                          အမျိုးသမီးများနှင့်ကျန်းမာရေး\n",
      "3                       မီးတွင်းကာလ ခေါင်းကိုက်ခြင်းများ\n",
      "4                                                      5\n",
      "...                                                  ...\n",
      "29721                                                  »\n",
      "29722                            ကလေးများနှင့်ကျန်းမာရေး\n",
      "29723                                                  4\n",
      "29724                                                  5\n",
      "29725            ●        ပစ္စည်းတစ်ခုခု မျိုမိခြင်း ...\n",
      "\n",
      "[29726 rows x 1 columns]\n",
      "                                                     0                 idx\n",
      "0                                   သွေးတိုး ကျ စေ တယ်    idx_new_health_0\n",
      "1                              ဆီးချို တိုင်း ကြည့် ပါ    idx_new_health_1\n",
      "2                                ဆီးချို အတွက် ဆေး လား    idx_new_health_2\n",
      "3                                  သွေးတိုး နေ လို့ ပါ    idx_new_health_3\n",
      "4                             ဆီးချို ကို လဲ ကျ စေ တယ်    idx_new_health_4\n",
      "..                                                 ...                 ...\n",
      "691  ၀က်တစ်သျှူး လို အရာ တွေ က တော့ လက် ကို သုတ် မယ...  idx_new_health_313\n",
      "692  ကိုရိုနာ ဗိုင်းရပ်စ် ကူးစက် ခံ ရ သော ကလေး များ...  idx_new_health_314\n",
      "693                                ချက်ချင်း လျှော် ပါ  idx_new_health_315\n",
      "694                                 သေချာ အခြောက်ခံ ပါ  idx_new_health_316\n",
      "695  အဝတ် တွေ ကို ခါ တာ မျိုး မ လုပ် ပါ နဲ့ ပိုး တွ...  idx_new_health_317\n",
      "\n",
      "[696 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df_raw = pandas.read_csv(\"resources/raw_data.csv\")\n",
    "df_healthcare = pandas.read_csv(\"resources/29_dec_healthcare_new.csv\")\n",
    "\n",
    "print(df_raw)\n",
    "print(df_healthcare)\n",
    "\n",
    "grouped_raw = \n",
    "\n",
    "grouped_healthcare =\n",
    "\n",
    "\n",
    "grouped = df_student.groupby('school_code').agg({\"age\":['mean', 'min', 'max']})\n",
    "\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d0111",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Write a Pandas program to split a dataset to group by two columns and count by each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59085a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03767479",
   "metadata": {},
   "source": [
    "## Exercise 6 \n",
    "\n",
    "Write a Pandas program to split a dataset to group by two columns and then sort the aggregated results within the groups.\n",
    "\n",
    "In the following dataset **group on** 'customer_id', 'salesman_id' and then **sort** sum of purch_amt within the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a9af3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m df_orders \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresources/purchases_order.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m grouped \u001b[38;5;241m=\u001b[39m df_orders\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalesman_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgrouped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalesman_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python_ml/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:904\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m--> 904\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df_orders = pandas.read_csv(\"resources/purchases_order.csv\")\n",
    "\n",
    "grouped = df_orders.groupby([\"customer_id\", \"salesman_id\"])\n",
    "\n",
    "print(grouped.sort_values(by=[\"salesman_id\"], inplace = True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1bff77",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "\n",
    "Write a Pandas program to split the following dataframe into groups and calculate monthly purchase amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cfcaf",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "Write a Pandas program to split the following datasets into groups on customer id and calculate the number of customers starting with 'C', the list of all products and the difference of maximum purchase amount and minimum purchase amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ff16e",
   "metadata": {},
   "source": [
    "## Exercise 9\n",
    "\n",
    "Write a Pandas program to split a given dataset, group by one column and apply an aggregate function to few columns and another aggregate function to the rest of the columns of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e977b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T15:09:43.202399Z",
     "start_time": "2022-07-29T15:09:43.179629Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"resources/sales_dataset.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb23ea3",
   "metadata": {},
   "source": [
    "# join two dataframes along rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece95fd3",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Write a Pandas program to join the two given dataframes **along rows** and assign all data using pd.concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceaac87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T15:10:57.813635Z",
     "start_time": "2022-07-29T15:10:57.787506Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675c63a",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Join two dataframes **along columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847090a0",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Write a Pandas program to join the two given dataframes along rows and merge with another dataframe along the common column id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396244a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T15:12:32.114157Z",
     "start_time": "2022-07-29T15:12:32.050196Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "exam_data = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13'],\n",
    "        'exam_id': [23, 45, 12, 67, 21, 55, 33, 14, 56, 83, 88, 12]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb9539",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Write a Pandas program to join the two dataframes using the common column of both dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874406a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7afb3fb3",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Write a Pandas program to join the two dataframes with matching records from both sides where available. Write a Pandas program to join (left join) the two dataframes using keys from left dataframe only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223d0fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T15:15:44.268812Z",
     "start_time": "2022-07-29T15:15:44.254356Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']}) \n",
    "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "                      'S': ['S0', 'S1', 'S2', 'S3']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc609b5",
   "metadata": {},
   "source": [
    "# Healthcare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323565a1",
   "metadata": {},
   "source": [
    "read csv files named \n",
    "raw_data.csv, 29_dec_healthcare_new.csv \n",
    "MT_data_from_raw - covid_faq.csv from resources folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d30e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T15:17:40.162764Z",
     "start_time": "2022-07-29T15:17:40.100950Z"
    }
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('resources/raw_data.csv')\n",
    "df_healthcare = pd.read_csv('resources/29_dec_healthcare_new.csv')\n",
    "df_covid = pd.read_csv('resources/MT_data_from_raw - covid_faq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c6be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T15:17:58.588919Z",
     "start_time": "2022-07-29T15:17:58.575797Z"
    }
   },
   "outputs": [],
   "source": [
    "df_healthcare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7bf165",
   "metadata": {},
   "source": [
    "## make all csv with the same column names and index. Then combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dad584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d296c94",
   "metadata": {},
   "source": [
    "## drop nan rows and duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7818fb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c48492ad",
   "metadata": {},
   "source": [
    "## Split the sentences with \"\\n and ။\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e87590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfdee1bd",
   "metadata": {},
   "source": [
    "## Get sentence length of each rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85598cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f16260",
   "metadata": {},
   "source": [
    "## remove punctuations from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ea254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97cd7628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T13:21:11.723649Z",
     "start_time": "2022-07-29T13:21:11.719570Z"
    }
   },
   "source": [
    "## lower all english sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee2ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f32cc9c",
   "metadata": {},
   "source": [
    "## get sentences with covid keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3a8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf8f365",
   "metadata": {},
   "source": [
    "## get sentences with burmese end words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac54015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
